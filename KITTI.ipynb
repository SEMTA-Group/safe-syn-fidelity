{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import Kitti\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_number = 4\n",
    "torch.manual_seed(seed_number)\n",
    "np.random.seed(seed_number)\n",
    "random.seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f20997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2966c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download and load the KITTI dataset\n",
    "kitti_real_dataset = Kitti(root='data/data_real/',  transform=ToTensor(), download = False)\n",
    "kitti_syn_dataset = Kitti(root='data/data_syn_Carla/',  transform=ToTensor(), download = False)\n",
    "\n",
    "# Get the k-th image in the list () and its ground truth labels\n",
    "image_index = 0\n",
    "\n",
    "# Note that label_real and label_syn are the same\n",
    "image_real, label_real = kitti_real_dataset[image_index]\n",
    "image_syn, label_syn  = kitti_syn_dataset[image_index]\n",
    "\n",
    "# Display the image with the bounding box\n",
    "fig_real, ax = plt.subplots(1)\n",
    "ax.imshow(image_real.permute(1, 2, 0))\n",
    "for box in label_real:\n",
    "    bbox = box[\"bbox\"]\n",
    "    x1 = bbox[0]\n",
    "    y1 = bbox[1]\n",
    "    x2 = bbox[2]\n",
    "    y2 = bbox[3]\n",
    "    #x1, y1, x2, y2 = box\n",
    "\n",
    "    if box[\"type\"] == \"Pedestrian\":\n",
    "        ax.text((x1+x2)/2, y1, 'pedestrian', ha='center', va='bottom', transform=ax.transData, fontsize=8, color='red')\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=1)\n",
    "    elif box[\"type\"] == \"Car\":\n",
    "        ax.text((x1+x2)/2, y1, 'car', ha='center', va='bottom', transform=ax.transData, fontsize=8, color='green')\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='green', linewidth=1)\n",
    "    elif box[\"type\"] == \"Van\":\n",
    "        ax.text((x1+x2)/2, y1, 'van', ha='center', va='bottom', transform=ax.transData, fontsize=8, color='blue')\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='blue', linewidth=1)\n",
    "    elif box[\"type\"] == \"Truck\":\n",
    "        ax.text((x1+x2)/2, y1, 'truck', ha='center', va='bottom', transform=ax.transData, fontsize=8, color='orange')\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='orange', linewidth=1)\n",
    "    else:\n",
    "        # For the other classes, we use gray\n",
    "        ax.text((x1+x2)/2, y1, box[\"type\"], ha='center', va='bottom', transform=ax.transData, fontsize=8, color='gray')\n",
    "        \n",
    "    ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "fig_syn, ax = plt.subplots(1)\n",
    "ax.imshow(image_syn.permute(1, 2, 0))\n",
    "for box in label_syn:\n",
    "    bbox = box[\"bbox\"]\n",
    "    x1 = bbox[0]\n",
    "    y1 = bbox[1]\n",
    "    x2 = bbox[2]\n",
    "    y2 = bbox[3]\n",
    "    #x1, y1, x2, y2 = box\n",
    "\n",
    "    if box[\"type\"] == \"Pedestrian\":\n",
    "        ax.text((x1+x2)/2, y1, 'pedestrian', ha='center', va='bottom', transform=ax.transData, fontsize=8, color='red')\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=1)\n",
    "    elif box[\"type\"] == \"Car\":\n",
    "        ax.text((x1+x2)/2, y1, 'car', ha='center', va='bottom', transform=ax.transData, fontsize=8, color='green')\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='green', linewidth=1)\n",
    "    elif box[\"type\"] == \"Van\":\n",
    "        ax.text((x1+x2)/2, y1, 'van', ha='center', va='bottom', transform=ax.transData, fontsize=8, color='blue')\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='blue', linewidth=1)\n",
    "    elif box[\"type\"] == \"Truck\":\n",
    "        ax.text((x1+x2)/2, y1, 'truck', ha='center', va='bottom', transform=ax.transData, fontsize=8, color='orange')\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='orange', linewidth=1)\n",
    "    else:\n",
    "        # For the other classes, we use gray\n",
    "        ax.text((x1+x2)/2, y1, box[\"type\"], ha='center', va='bottom', transform=ax.transData, fontsize=8, color='gray')\n",
    "        \n",
    "    ax.add_patch(rect)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import Kitti\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the pre-trained model\n",
    "#model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model = torchvision.models.detection.ssd300_vgg16(pretrained=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "# Get an image from the KITTI dataset\n",
    "image_real, _ = kitti_real_dataset[0]\n",
    "image_real = image_real.to(device)\n",
    "\n",
    "# Generate predictions for the image\n",
    "with torch.no_grad():\n",
    "    prediction = model([image_real])\n",
    "\n",
    "# Display the image with the predicted bounding boxes\n",
    "image_real = image_real.cpu()\n",
    "prediction = prediction[0]\n",
    "boxes = prediction['boxes'].cpu().numpy()\n",
    "scores = prediction['scores'].cpu().numpy()\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image_real.permute(1, 2, 0))\n",
    "for box, score in zip(boxes, scores):\n",
    "    if score > 0.5:\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=1)\n",
    "        ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Get an image from the KITTI dataset\n",
    "image_syn, _ = kitti_syn_dataset[0]\n",
    "image_syn = image_syn.to(device)\n",
    "\n",
    "# Generate predictions for the image\n",
    "with torch.no_grad():\n",
    "    prediction = model([image_syn])\n",
    "\n",
    "# Display the image with the predicted bounding boxes\n",
    "image_syn = image_syn.cpu()\n",
    "prediction = prediction[0]\n",
    "boxes = prediction['boxes'].cpu().numpy()\n",
    "scores = prediction['scores'].cpu().numpy()\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image_syn.permute(1, 2, 0))\n",
    "for box, score in zip(boxes, scores):\n",
    "    if score > CONFIDENCE_THRESHOLD:\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=1)\n",
    "        ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1addcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundingBox:\n",
    "    def __init__(self, x1, y1, x2, y2):\n",
    "        self.x1 = x1\n",
    "        self.y1 = y1\n",
    "        self.x2 = x2\n",
    "        self.y2 = y2\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    x_left = max(box1.x1, box2.x1)\n",
    "    y_top = max(box1.y1, box2.y1)\n",
    "    x_right = min(box1.x2, box2.x2)\n",
    "    y_bottom = min(box1.y2, box2.y2)\n",
    "\n",
    "    # Calculate area of intersection\n",
    "    intersection_area = max(0, x_right - x_left) * max(0, y_bottom - y_top)\n",
    "\n",
    "    # Calculate areas of the input boxes\n",
    "    box1_area = (box1.x2 - box1.x1) * (box1.y2 - box1.y1)\n",
    "    box2_area = (box2.x2 - box2.x1) * (box2.y2 - box2.y1)\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "def count_undetected_objects(ground_truths, predictions, iou_threshold, size_gt = 0):\n",
    "    undetected_count = 0\n",
    "    count_smaller = 0\n",
    "    undetected_count_smaller = 0\n",
    "\n",
    "    for gt_box in ground_truths:\n",
    "        area = (gt_box.x2 - gt_box.x1) * (gt_box.y2 - gt_box.y1)        \n",
    "        if area >= size_gt:\n",
    "            detected = False\n",
    "            for pred_box in predictions:\n",
    "                if calculate_iou(gt_box, pred_box) >= iou_threshold:\n",
    "                    detected = True\n",
    "                    break\n",
    "            if not detected:\n",
    "                undetected_count += 1\n",
    "        else:\n",
    "            count_smaller += 1\n",
    "            detected = False\n",
    "            for pred_box in predictions:\n",
    "                if calculate_iou(gt_box, pred_box) >= iou_threshold:\n",
    "                    detected = True\n",
    "                    break\n",
    "            if not detected:\n",
    "                undetected_count_smaller += 1            \n",
    "\n",
    "\n",
    "    return undetected_count, count_smaller, undetected_count_smaller\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae568f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6606b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AREA_THRESHOLD = 0\n",
    "\n",
    "bounding_boxes_real = list()\n",
    "bounding_boxes_syn = list()\n",
    "\n",
    "# Get an image from the KITTI dataset\n",
    "image_real, _ = kitti_real_dataset[0]\n",
    "image_real = image_real.to(device)\n",
    "\n",
    "# Generate predictions for the image\n",
    "with torch.no_grad():\n",
    "    prediction_real = model([image_real])\n",
    "\n",
    "# Display the image with the predicted bounding boxes\n",
    "image_real = image_real.cpu()\n",
    "prediction_real = prediction_real[0]\n",
    "boxes_real = prediction_real['boxes'].cpu().numpy()\n",
    "scores_real = prediction_real['scores'].cpu().numpy()\n",
    "\n",
    "for box_real, score_real in zip(boxes_real, scores_real):\n",
    "    if score_real > CONFIDENCE_THRESHOLD:\n",
    "        x1, y1, x2, y2 = box_real\n",
    "        bounding_boxes_real.append(BoundingBox(x1, y1, x2, y2))\n",
    "\n",
    "# Get an image from the KITTI dataset\n",
    "image_syn, _ = kitti_syn_dataset[0]\n",
    "image_syn = image_syn.to(device)\n",
    "\n",
    "# Generate predictions for the image\n",
    "with torch.no_grad():\n",
    "    prediction = model([image_syn])\n",
    "\n",
    "# Display the image with the predicted bounding boxes\n",
    "image_syn = image_syn.cpu()\n",
    "prediction_syn = prediction[0]\n",
    "boxes_syn = prediction_syn['boxes'].cpu().numpy()\n",
    "scores_syn = prediction_syn['scores'].cpu().numpy()\n",
    "\n",
    "for box_syn, score_syn in zip(boxes_syn, scores_syn):\n",
    "    if score_syn > CONFIDENCE_THRESHOLD:\n",
    "        x1, y1, x2, y2 = box_syn\n",
    "        bounding_boxes_syn.append(BoundingBox(x1, y1, x2, y2))\n",
    "\n",
    "undetected_count, count_smaller, undetected_count_smaller = count_undetected_objects(bounding_boxes_real, bounding_boxes_syn, IOU_THRESHOLD, AREA_THRESHOLD)\n",
    "\n",
    "print(\"=== Summary comparing the detector in real and syn ===\")\n",
    "print(\"Detected in real, but undetected in syn (area larger than threshold):\", undetected_count)\n",
    "print(\"Detected objects in real; area smaller than threshold:\", count_smaller)\n",
    "print(\"Detected in real, but undetected in syn (area smaller than threshold):\", undetected_count_smaller)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc1a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
